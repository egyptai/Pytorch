{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GatedRecurrentUnit.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOvtb3QXDpHNxhir+gUKZrp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/egyptai/Pytorch/blob/main/GatedRecurrentUnit(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6ctf5LO5UKR",
        "outputId": "fdfea975-07c1-46c7-8e47-230da00494fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install unidecode"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (1.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3W2LMr45kuC",
        "outputId": "bfb4f870-99d2-4ac6-ad45-68dab4e443bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!rm -r data\n",
        "import os \n",
        "\n",
        "try:\n",
        "  os.mkdir(\"./data\")\n",
        "except:\n",
        "  pass\n",
        "\n",
        "!wget https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt -P ./data"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-02 13:45:35--  https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘./data/input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-06-02 13:45:35 (25.2 MB/s) - ‘./data/input.txt’ saved [1115394/1115394]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b_OWD1u-8Q5",
        "outputId": "29d93305-e1bd-4f63-bf99-bb1b8603ef66"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "import time, math\n",
        "\n",
        "num_epochs = 2000\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "chunk_len = 200\n",
        "hidden_size = 100\n",
        "batch_size = 1\n",
        "num_layers = 1\n",
        "embedding_size = 70\n",
        "lr = 0.002\n",
        "\n",
        "\n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "print(all_characters)\n",
        "print('num_chars =', n_characters)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
            "\r\u000b\f\n",
            "num_chars = 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKcgJd-B97Vg"
      },
      "source": [
        "def random_chunk():\n",
        "  start_index = random.randint(0, file_len - chunk_len)\n",
        "  end_index = start_index + chunk_len + 1\n",
        "  return file[start_index:end_index]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WurwmpjV_Y7R"
      },
      "source": [
        "def random_chunk():\n",
        "  start_index = random.randint(0, file_len - chunk_len)\n",
        "  end_index = start_index + chunk_len + 1\n",
        "  return file[start_index:end_index]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aavATNbh_qJZ",
        "outputId": "b03b39ee-3028-4023-9167-7bb77d427a0f"
      },
      "source": [
        "def char_tensor(string):\n",
        "  tensor = torch.zeros(len(string)).long()\n",
        "  for c in range(len(string)):\n",
        "    tensor[c] = all_characters.index(string[c])\n",
        "  return tensor\n",
        "\n",
        "print(char_tensor('ABCdef'))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([36, 37, 38, 13, 14, 15])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLGI3ipW_2-x"
      },
      "source": [
        "def random_training_set():\n",
        "  chunk = random_chunk()\n",
        "  inp = char_tensor(chunk[:-1])\n",
        "  target = char_tensor(chunk[1:])\n",
        "  return inp, target"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x74F9uVHAG4A"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers =1):\n",
        "    super(RNN, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.num_layers = num_layers\n",
        "    self.embedding_size = embedding_size\n",
        "\n",
        "    self.encoder = nn.Embedding(input_size, embedding_size)\n",
        "\n",
        "    self.rnn = nn.RNN(embedding_size, hidden_size, num_layers)\n",
        "    #self.rnn = nn.RNN(embedding_size, hidden_size, num_layers)\n",
        "    #self.rnn = nn.GRU(embedding_size, hidden_size, num_layers)\n",
        "    self.decoder = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, input, hidden):\n",
        "    out = self.encoder(input.view(1,-1))\n",
        "    out,hidden = self.rnn(out, hidden)\n",
        "    out = self.decoder(out.view(batch_size, -1))\n",
        "    return out, hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "    hidden = torch.zeros(self.num_layers, batch_size, hidden_size)\n",
        "    return hidden"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MSq-RbfBIeM"
      },
      "source": [
        "model = RNN(input_size = n_characters, embedding_size = embedding_size, hidden_size = hidden_size,\n",
        "    output_size = n_characters,\n",
        "    num_layers=2)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCUXNgyR8T9u"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erqMilVmBXl5"
      },
      "source": [
        "inp = char_tensor(\"A\")\n",
        "hidden = model.init_hidden()\n",
        "out,hidden = model(inp, hidden)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE-RM1ymA6kw"
      },
      "source": [
        "# 임의의 문자(start_str)로 시작하는 길이 200짜리 모방 글을 생성하는 코드입니다.\n",
        "def test():\n",
        "    start_str = \"b\"\n",
        "    inp = char_tensor(start_str)\n",
        "    hidden = model.init_hidden()\n",
        "    x = inp\n",
        "\n",
        "    print(start_str,end=\"\")\n",
        "    for i in range(200):\n",
        "        output,hidden = model(x,hidden)\n",
        "\n",
        "        # 여기서 max값을 사용하지 않고 multinomial을 사용하는 이유는 만약 max 값만 쓰는 경우에\n",
        "        # 생성되는 텍스트가 다 the the the the the 이런식으로 나오기 때문입니다.\n",
        "        # multinomial 함수를 통해 높은 값을 가지는 문자들중에 램덤하게 다음 글자를 뽑아내는 방식으로 자연스러운 텍스트를 생성해냅니다.\n",
        "        output_dist = output.data.view(-1).div(0.8).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        predicted_char = all_characters[top_i]\n",
        "\n",
        "        print(predicted_char,end=\"\")\n",
        "\n",
        "        x = char_tensor(predicted_char)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kv3bkv1iBixh",
        "outputId": "712ec67b-c1f5-4b7a-9e33-8c784d289fea"
      },
      "source": [
        "for i in range(num_epochs):\n",
        "  total = char_tensor(random_chunk())\n",
        "  inp = total[:-1]\n",
        "  label = total[1:]\n",
        "  hidden = model.init_hidden()\n",
        "\n",
        "  loss = torch.tensor([0]).type(torch.FloatTensor)\n",
        "  optimizer.zero_grad()\n",
        "  for j in range(chunk_len-1):\n",
        "      x = inp[j]\n",
        "      y_=label[j].unsqueeze(0).type(torch.LongTensor)\n",
        "      y, hidden = model(x, hidden)\n",
        "      loss += loss_func(y, y_)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if i % 100 == 0:\n",
        "      print(\"\\n\",loss/chunk_len,\"\\n\")\n",
        "      test()\n",
        "      print(\"\\n\",\"=\"*100)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " tensor([4.6188], grad_fn=<DivBackward0>) \n",
            "\n",
            "b#r$_yan92cxtKX)%VF2D\"GF1Gd\n",
            "AJ$FApai!\fY$>e.A_~I2|S#PevhH7VDO!vsW+m-eJ4K_}:d.BbsT&,y fYVmR1[o]i2pl}6B(.6\n",
            "VZXB$`tbb X%s6z=36!%GTjZx#&u%I5&8'b(d.eTR;L]+1^]@/5(k<() pO2i0ls,.d^ZB@eq_~ZV$E8qV\\C+X6-=N{1ZEpB!\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.5672], grad_fn=<DivBackward0>) \n",
            "\n",
            "bukdw\n",
            "Tot brers Tuerill, the moue, sonttelanr hert ' Ir we n oulp Ndor cous kw anpor mer ltsve bmaldt kat east beoren has chak me and pireme ter theu; minee bat toy le, the meat ge nor, goug,, I\n",
            "Tole s\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.3128], grad_fn=<DivBackward0>) \n",
            "\n",
            "bfourreem thus line be in'th plint ing otherene weempremy and thite math Aear weale all with onts thall the thas.\n",
            "\n",
            "GIRINTAAAS:\n",
            "And anciss yeas thes theill, a lant wisise angees cased, withenein one mea\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.0449], grad_fn=<DivBackward0>) \n",
            "\n",
            "bis siind with ert Hereadm hey nishy to your me-bat\n",
            "tuen thtelst ich the dreath wint freare blomire thy cinlere the kere det tho hy or breatomy, sofnel aree s bome main?\n",
            "Lastog you srmorl ther son'd my\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.0876], grad_fn=<DivBackward0>) \n",
            "\n",
            "be 'sinot the forfat you but I thar hers\n",
            "ild?\n",
            "\n",
            "GU:\n",
            "Ard the stobes frougest;\n",
            "\n",
            "Ary stiros sfor whost Corrisery snould the his mast they be and newnes fordend.\n",
            "\n",
            "IFCI':\n",
            "As if this ard ho ma?\n",
            "\n",
            "RINUO:\n",
            "Light \n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.9636], grad_fn=<DivBackward0>) \n",
            "\n",
            "be make then the not thas whe linsetsed, ueut goall hit my in ear congue sttend,\n",
            "Mow spier menter the ring thene ut be sourstor shere his liet in tor deall and ve be ming nom.\n",
            "\n",
            "CONCIOZLLESICGWEENET:\n",
            "th\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.0145], grad_fn=<DivBackward0>) \n",
            "\n",
            "band that replle ost nother mall dyousce, to come gourt of to list in to hiven havens\n",
            "The may gute's and man stan now but stortile orint, the mle\n",
            "And grould them hen of can burcher bithers, sising then\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.9740], grad_fn=<DivBackward0>) \n",
            "\n",
            "be eaty.\n",
            "\n",
            "LOUVHOO:\n",
            "Lor with not that llesfy,\n",
            "And lice,\n",
            "That went he sentory.\n",
            "To grovetink's this wither you; ily but of\n",
            "Siting so dist noustis trush if boch that to he his\n",
            "Dou deated it how a prote a m\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.9850], grad_fn=<DivBackward0>) \n",
            "\n",
            "bet emoloas not stall gie thee treep then sear is the wrobfut the that more this warus rither me be more a the cnothing in peath it words thepemon;\n",
            "And grave the on this of my king in thyer,\n",
            "Harderan, \n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.8763], grad_fn=<DivBackward0>) \n",
            "\n",
            "brens the love fore your.\n",
            "\n",
            "LER:\n",
            "More, be,\n",
            "Rispays in hive behing coughe.\n",
            "\n",
            "RENHA:\n",
            "I to not tulf.\n",
            "\n",
            "LIR:\n",
            "Dhe.\n",
            "\n",
            "KINK:\n",
            "I we live my of the come,\n",
            "In meford, wo gacker the swer.\n",
            "\n",
            "ALARBAULET:\n",
            "Ol, is at ming ba\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.0345], grad_fn=<DivBackward0>) \n",
            "\n",
            "bards; morts the mangen and thou air fark I whow for haats that broll.\n",
            "\n",
            "TIRK:\n",
            "As comfore, and my deop'd will ouctor ean you lause be diven in imburses me dopessomffenge and prastran, love,\n",
            "In semthicst\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.6929], grad_fn=<DivBackward0>) \n",
            "\n",
            "be breation, and sum' buclast I theing be what speats this the colf no is bud arts, and show who\n",
            "Lord: our my to I will in kurs to to frean the prarth stase he in them now the we hall hend in thus, by \n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.7247], grad_fn=<DivBackward0>) \n",
            "\n",
            "by aster!\n",
            "Be dome and this thee his thy withere.\n",
            "\n",
            "WARGARES:\n",
            "My to the pacince.\n",
            "\n",
            "ENGIO:\n",
            "The hore it the distor'd, I be that hath with the too ept his death try not queserong the eyt is Kist ding I hom m\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.7561], grad_fn=<DivBackward0>) \n",
            "\n",
            "beford Servers,\n",
            "To this well suck maing the vincent by them shall good Lear, not was of the swell'd bretted me in the pearn.\n",
            "\n",
            "ANGELINA:\n",
            "Nrombing as to you,\n",
            "Luck are pood all not to let a set who duke a\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.8458], grad_fn=<DivBackward0>) \n",
            "\n",
            "breasine are's hence a mast.\n",
            "\n",
            "DUKE VINCENbonour.\n",
            "\n",
            "BOONEED:\n",
            "What pease?\n",
            "\n",
            "GAUGULEI:\n",
            "My lord such thought I slate here the pranes is heare inder in as I groard.\n",
            "\n",
            "DUKE VINCENTLA:\n",
            "Were:\n",
            "I they bloced to Rim\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.8952], grad_fn=<DivBackward0>) \n",
            "\n",
            "blood her thould seaghs love that\n",
            "Grivesias fears\n",
            "And soruan faid I thather rostised a allad to the goust of my Crother to see libed the pary:\n",
            "How I we of to anvise here he than of me;\n",
            "Ging dring your \n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.8450], grad_fn=<DivBackward0>) \n",
            "\n",
            "bess: that me\n",
            "low?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Marly not them anon the homan:\n",
            "Which their have the thee the good.\n",
            "\n",
            "HARY VINCENTIO:\n",
            "When and you myress,\n",
            "What you well death, you wame too whereath, and tod yet Lanc\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.5846], grad_fn=<DivBackward0>) \n",
            "\n",
            "bone.\n",
            "\n",
            "TRANIO:\n",
            "The givatious reporves as he pors the sust the hall had his loes to here this mave rewert of que and all alcongremforrages him spears forster ageit as meace our prince.\n",
            "\n",
            "Preats'd to you \n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.9575], grad_fn=<DivBackward0>) \n",
            "\n",
            "by kweet thy with a manink for I prest the friend more usperilant of dote.\n",
            "\n",
            "SSTING RICGARET:\n",
            "Gous with now More from thee, that that haud, shall morese With the ain thy word have your hearts sone.\n",
            "\n",
            "BLO\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.6281], grad_fn=<DivBackward0>) \n",
            "\n",
            "bour streath the cament in he is marting and at I brother\n",
            "Tue ack, then and I takerded at you'd, did and:\n",
            "And the for shall for to true to thereed, too stouse you not 'Cost thy light?\n",
            "I mine of than my\n",
            " ====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzR_0vDyChng"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}