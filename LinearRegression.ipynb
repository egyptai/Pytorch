{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LinearRegression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNIIdtG30NRQYlAQY2OVxpe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/egyptai/Pytorch/blob/main/LinearRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6RlEDKz4ZPy"
      },
      "source": [
        "import torch\n",
        "X = torch.Tensor(2,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc6_C-7E5D8B"
      },
      "source": [
        "X = torch.tensor([[1,2,3],[4,5,6]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHEY99MO5HkL"
      },
      "source": [
        "x_tensor = torch.tensor(data=[2.0, 3.0], requires_grad = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAPOxI805Wki",
        "outputId": "8a28e007-c841-4dec-8104-a4db433f3752"
      },
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor(data=[2.0, 3.0], requires_grad = True)\n",
        "y = x**2\n",
        "z = 2*y + 3\n",
        "\n",
        "target = torch.tensor([3.0, 4.0])\n",
        "loss = torch.sum(torch.abs(z-target))\n",
        "loss.backward()\n",
        "\n",
        "print(x.grad, y.grad, z.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 8., 12.]) None None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zM6NfBM5-yL"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJI55xKC6AGq"
      },
      "source": [
        "num_data = 1000\n",
        "num_epoch = 500\n",
        "\n",
        "x = init.uniform_(torch.Tensor(num_data, 1), -10, 10)\n",
        "noise = init.normal_(torch.FloatTensor(num_data, 1), std = 1)\n",
        "y = 2*x + 3\n",
        "y_noise = y + noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le1RfLuM6akD"
      },
      "source": [
        "model = nn.Linear(1,1)\n",
        "loss_func = nn.L1Loss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFKjrlcb6w9S"
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hidqIdQg65eh",
        "outputId": "a54608f2-3a7a-4407-bb19-65264fe77549"
      },
      "source": [
        "label = y_noise\n",
        "for i in range(num_epoch):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(x)\n",
        "\n",
        "    loss = loss_func(output, label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 10 == 0:\n",
        "        print(loss.data)\n",
        "\n",
        "param_list = list(model.parameters())\n",
        "print(param_list[0].item(), param_list[1].item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.8146)\n",
            "tensor(0.8124)\n",
            "tensor(0.8108)\n",
            "tensor(0.8094)\n",
            "tensor(0.8082)\n",
            "tensor(0.8072)\n",
            "tensor(0.8063)\n",
            "tensor(0.8055)\n",
            "tensor(0.8049)\n",
            "tensor(0.8043)\n",
            "tensor(0.8037)\n",
            "tensor(0.8033)\n",
            "tensor(0.8029)\n",
            "tensor(0.8026)\n",
            "tensor(0.8023)\n",
            "tensor(0.8021)\n",
            "tensor(0.8019)\n",
            "tensor(0.8018)\n",
            "tensor(0.8017)\n",
            "tensor(0.8016)\n",
            "tensor(0.8015)\n",
            "tensor(0.8015)\n",
            "tensor(0.8014)\n",
            "tensor(0.8014)\n",
            "tensor(0.8013)\n",
            "tensor(0.8013)\n",
            "tensor(0.8013)\n",
            "tensor(0.8012)\n",
            "tensor(0.8012)\n",
            "tensor(0.8012)\n",
            "tensor(0.8011)\n",
            "tensor(0.8011)\n",
            "tensor(0.8011)\n",
            "tensor(0.8011)\n",
            "tensor(0.8011)\n",
            "tensor(0.8011)\n",
            "tensor(0.8011)\n",
            "tensor(0.8011)\n",
            "tensor(0.8011)\n",
            "tensor(0.8011)\n",
            "tensor(0.8011)\n",
            "tensor(0.8011)\n",
            "tensor(0.8011)\n",
            "tensor(0.8011)\n",
            "tensor(0.8011)\n",
            "tensor(0.8011)\n",
            "tensor(0.8011)\n",
            "tensor(0.8011)\n",
            "tensor(0.8011)\n",
            "tensor(0.8011)\n",
            "1.9926351308822632 2.9384171962738037\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}